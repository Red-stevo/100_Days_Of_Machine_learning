{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f79aea-f31b-42d2-88d1-793212dc41fc",
   "metadata": {},
   "source": [
    "# Dogs cats classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27b949e3-09b2-453b-bded-f1e0c8e261e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4086c-ce57-46ea-86c6-e03ef05075e0",
   "metadata": {},
   "source": [
    "# Train test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5b2ecc7-6282-4c7a-84b2-497180f94141",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cats_path = \"../../Documents/Datasets/PetImages/cat/\"\n",
    "all_dogs_path = \"../../Documents/Datasets/PetImages/dog/\"\n",
    "\n",
    "# number of cat images.\n",
    "num_cats = len(os.listdir(all_cats_path))\n",
    "\n",
    "# number of dogs images\n",
    "num_dogs = len(os.listdir(all_dogs_path))\n",
    "\n",
    "if os.path.isdir(\"../../Documents/Datasets/PetImages/train/cat\") is False:\n",
    "    os.mkdir(\"../../Documents/Datasets/PetImages/train/cat\", )\n",
    "    os.mkdir(\"../../Documents/Datasets/PetImages/train/dog\")\n",
    "    os.mkdir(\"../../Documents/Datasets/PetImages/test/cat\")\n",
    "    os.mkdir(\"../../Documents/Datasets/PetImages/test/dog\")\n",
    "\n",
    "    for image in random.sample(glob.glob(all_cats_path+\"*\"), int(0.7 * num_cats)):\n",
    "        shutil.copy2(image, '../../Documents/Datasets/PetImages/train/cat')\n",
    "\n",
    "    for image in random.sample(glob.glob(all_dogs_path+\"*\"), int(0.7 * num_dogs)):\n",
    "        shutil.copy2(image, '../../Documents/Datasets/PetImages/train/dog')\n",
    "\n",
    "    for image in random.sample(glob.glob(all_cats_path+\"*\"), int(0.3 * num_cats)):\n",
    "        shutil.copy2(image, '../../Documents/Datasets/PetImages/test/cat')\n",
    "\n",
    "    for image in random.sample(glob.glob(all_dogs_path+\"*\"), int(0.3 * num_dogs)):\n",
    "        shutil.copy2(image, '../../Documents/Datasets/PetImages/test/dog')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a27c019-e651-4a1d-bea3-1b2e45714d6c",
   "metadata": {},
   "source": [
    "# Split the dataset to testing and training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01bbe660-1dce-4327-ac1c-9f601a3c994e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17498 images belonging to 2 classes.\n",
      "Found 7498 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Loading the dogs and cats data and preprocessing it.\n",
    "\n",
    "# images paths.\n",
    "train_data_path = \"../../Documents/Datasets/PetImages/train/\"\n",
    "test_data_path = \"../../Documents/Datasets/PetImages/test/\"\n",
    "\n",
    "\n",
    "# Preprocess the data.\n",
    "train_data = IDG(preprocessing_function=preprocess_input).flow_from_directory(directory=train_data_path, classes=[\"cat\", \"dog\"], batch_size=50, target_size=(300, 300))\n",
    "\n",
    "test_data = IDG(preprocessing_function=preprocess_input).flow_from_directory(directory=test_data_path, classes=[\"cat\", \"dog\"], batch_size=50, target_size=(300, 300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "418c9bf0-66bd-45d0-8263-3177275e7d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-28 13:18:20.391990: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">360000</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">720,002</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m360000\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │       \u001b[38;5;34m720,002\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">739,394</span> (2.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m739,394\u001b[0m (2.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">739,394</span> (2.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m739,394\u001b[0m (2.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(300, 300, 3)),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", padding='same'),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding='same'),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(activation=\"softmax\", units=2)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54473a1b-dd36-4baa-9f42-751cda9ba2e6",
   "metadata": {},
   "source": [
    "# fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2f34393-17df-4c4b-b393-ce0aef465330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m187/350\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10:14\u001b[0m 4s/step - accuracy: 0.5714 - loss: 4.2200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/deep-learning-env/lib/python3.13/site-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1341s\u001b[0m 4s/step - accuracy: 0.5964 - loss: 3.4105\n",
      "Epoch 2/5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1362s\u001b[0m 4s/step - accuracy: 0.6503 - loss: 2.2404\n",
      "Epoch 3/5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1392s\u001b[0m 4s/step - accuracy: 0.7054 - loss: 1.4986\n",
      "Epoch 4/5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1357s\u001b[0m 4s/step - accuracy: 0.7355 - loss: 1.2246\n",
      "Epoch 5/5\n",
      "\u001b[1m350/350\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1398s\u001b[0m 4s/step - accuracy: 0.7799 - loss: 0.8250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x725d104fd810>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_data, verbose=True, epochs=5, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34cbbefe-6825-475e-93d1-94ff2a36d530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steve/deep-learning-env/lib/python3.13/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.9824512e-10, 9.9999994e-01],\n",
       "       [9.8676300e-01, 1.3237066e-02],\n",
       "       [9.4606245e-01, 5.3937539e-02],\n",
       "       ...,\n",
       "       [2.7750908e-05, 9.9997216e-01],\n",
       "       [6.9030708e-01, 3.0969295e-01],\n",
       "       [9.9980855e-01, 1.9151330e-04]], shape=(7498, 2), dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15112129-1869-461b-9e9d-542e413458c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../../Documents/Datasets/PetImages/cat_dog_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ce855-0e8b-4608-b86a-c02c2a1ef198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
